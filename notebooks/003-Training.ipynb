{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.coordinator import Coordinator\n",
    "from src.utils.preprocessing import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = Coordinator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(coord.data_interim.joinpath('dataset_v1.jsonl'), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_types = {'musicians': ['taylorswift13', 'shakira', 'selenagomez', 'rihanna', 'katyperry', 'justinbieber', 'jtimberlake', 'britneyspears', \n",
    "                            'ArianaGrande', 'ladygaga'], \n",
    "             'politician': ['realDonaldTrump', 'narendramodi', 'BarackObama'],\n",
    "             'brand': ['YouTube', 'Twitter', 'cnnbrk'], \n",
    "             'entertainer': ['jimmyfallon', 'TheEllenShow'],\n",
    "             'media_personality': ['KimKardashian'],  \n",
    "             'sportsperson': ['Cristiano']}\n",
    "\n",
    "def get_user_type(user):\n",
    "    for user_type in user_types:\n",
    "        if user in user_types[user_type]:\n",
    "            return user_type\n",
    "\n",
    "df['user_type'] = df['user'].apply(get_user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user</th>\n",
       "      <th>time_epoch</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_likes</th>\n",
       "      <th>n_retweets</th>\n",
       "      <th>n_replies</th>\n",
       "      <th>n_emojis</th>\n",
       "      <th>quoted_tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>quoted_tweet_screen_name</th>\n",
       "      <th>quoted_tweet_name</th>\n",
       "      <th>quoted_tweet_hashtags</th>\n",
       "      <th>quoted_tweet_mentions</th>\n",
       "      <th>quoted_tweet_n_emojis</th>\n",
       "      <th>user_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249733419401183232</td>\n",
       "      <td>KimKardashian</td>\n",
       "      <td>1586794640</td>\n",
       "      <td>[restock, waist, trainer, clay, onyx, size, xx...</td>\n",
       "      <td>3850</td>\n",
       "      <td>166</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[skims]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>media_personality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1249338384847220738</td>\n",
       "      <td>KimKardashian</td>\n",
       "      <td>1586700457</td>\n",
       "      <td>[sweet, baby, true, happy, birthday, celebrate...</td>\n",
       "      <td>30039</td>\n",
       "      <td>1075</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>media_personality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1249080285972410368</td>\n",
       "      <td>KimKardashian</td>\n",
       "      <td>1586638921</td>\n",
       "      <td>[happen, text, message, iphone, blank, convers...</td>\n",
       "      <td>23384</td>\n",
       "      <td>797</td>\n",
       "      <td>2060</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>media_personality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           user  time_epoch  \\\n",
       "0  1249733419401183232  KimKardashian  1586794640   \n",
       "1  1249338384847220738  KimKardashian  1586700457   \n",
       "2  1249080285972410368  KimKardashian  1586638921   \n",
       "\n",
       "                                               tweet  n_likes  n_retweets  \\\n",
       "0  [restock, waist, trainer, clay, onyx, size, xx...     3850         166   \n",
       "1  [sweet, baby, true, happy, birthday, celebrate...    30039        1075   \n",
       "2  [happen, text, message, iphone, blank, convers...    23384         797   \n",
       "\n",
       "   n_replies  n_emojis quoted_tweet hashtags mentions  \\\n",
       "0        340         0                    []  [skims]   \n",
       "1        174         2                    []       []   \n",
       "2       2060         0                    []       []   \n",
       "\n",
       "  quoted_tweet_screen_name quoted_tweet_name quoted_tweet_hashtags  \\\n",
       "0                     None              None                    []   \n",
       "1                     None              None                    []   \n",
       "2                     None              None                    []   \n",
       "\n",
       "  quoted_tweet_mentions  quoted_tweet_n_emojis          user_type  \n",
       "0                    []                      0  media_personality  \n",
       "1                    []                      0  media_personality  \n",
       "2                    []                      0  media_personality  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor(lowercase=True, clean_links=True, clean_punctuation=True, expand_contractions=True, remove_stop_words=True, \n",
    "                                process_numbers='remove', normalization_type='lemma', clean_mentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tweet'].apply(lambda tweet: bool(tweet))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['tweet'], df['user_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20000, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor_tolmachev/.virtualenvs/information_retrieval_spbu/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(lowercase=False, max_features=50000,\n",
       "                tokenizer=<function <lambda> at 0x7ff2713ced90>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=False, tokenizer=lambda tokens: tokens, max_features=50000)\n",
    "tfidf.fit(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = tfidf.transform(X_train), tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.6 s, sys: 28.1 s, total: 1min 22s\n",
      "Wall time: 32.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor_tolmachev/.virtualenvs/information_retrieval_spbu/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8262"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.06 s, sys: 4.08 ms, total: 7.07 s\n",
      "Wall time: 7.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8446"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, y_train)\n",
    "linear_svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 20.1 s, total: 1min 26s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47535"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopicModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=6, random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=6, random_state=42)\n",
    "lda.fit(tfidf.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['president', 'trump', 'obama', 'great', 'vote', 'country', 'america', 'donald', 'people', 'job'] \n",
      "\n",
      "['india', 'people', 'shak', 'en', 'ji', 'la', 'development', 'work', 'nation', 'el'] \n",
      "\n",
      "['love', 'rt', 'happy', 'birthday', 'great', 'good', 'day', 'hope', 'time', 'today'] \n",
      "\n",
      "['police', 'kill', 'official', 'people', 'attack', 'death', 'suspect', 'report', 'shoot', 'dead'] \n",
      "\n",
      "['tonight', 'rt', 'love', 'fallontonight', 'watch', 'day', 'today', 'music', 'play', 'season'] \n",
      "\n",
      "['video', 'rt', 'love', 'क', 'wait', 'guy', 'watch', 'day', 'excite', 'today'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = tfidf.get_feature_names()\n",
    "\n",
    "n_top_words = 10\n",
    "\n",
    "topic_words = {}\n",
    "\n",
    "for topic, comp in enumerate(lda.components_):    \n",
    "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "    print([vocab[x] for x in word_idx],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 341 ms, total: 1min 17s\n",
      "Wall time: 25.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder().fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023316056291637462"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(kmeans.predict(X), le.transform(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "information_retrieval_spbu",
   "language": "python",
   "name": "information_retrieval_spbu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
